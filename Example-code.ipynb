{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c2e79e4",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6916448a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T15:22:25.492187Z",
     "start_time": "2025-06-20T15:22:25.150077Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_matrix shape: (300, 500, 6)\n",
      "mask_data shape: (300, 500, 6)\n",
      "\n",
      "masked_data Missing proportion: 2.00% (18000 / 900000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "path = r\"E:\\Code\\github\"\n",
    "\n",
    "\n",
    "mask_matrix = np.load(f\"{path}\\\\mask_matrix.npy\")\n",
    "mask_data = np.load(f\"{path}\\\\mask_data.npy\")\n",
    "\n",
    "\n",
    "print(\"mask_matrix shape:\", mask_matrix.shape)\n",
    "print(\"mask_data shape:\", mask_data.shape)\n",
    "\n",
    "total_elements = mask_data.size\n",
    "missing_elements = np.isnan(mask_data).sum()\n",
    "missing_ratio = missing_elements / total_elements\n",
    "\n",
    "print(f\"\\nmasked_data Missing proportion: {missing_ratio:.2%} ({missing_elements} / {total_elements})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "682aa29e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T15:22:44.185761Z",
     "start_time": "2025-06-20T15:22:44.166416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LS1 shape: (300, 300)\n",
      "LS2 shape: (500, 500)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "load_dir = r\"E:\\Code\\github\"\n",
    "\n",
    "# 读取\n",
    "LS1 = np.load(os.path.join(load_dir, \"LS1.npy\"))\n",
    "LS2 = np.load(os.path.join(load_dir, \"LS2.npy\"))\n",
    "\n",
    "print(\"LS1 shape:\", LS1.shape)\n",
    "print(\"LS2 shape:\", LS2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43376c07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T15:23:39.294537Z",
     "start_time": "2025-06-20T15:23:07.387361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train  - MSE: 0.0014, MAE: 0.0033, RMSE: 0.0368\n",
      "Val - MSE: 0.0014, MAE: 0.0033, RMSE: 0.0368\n",
      "Train  - MSE: 0.0006, MAE: 0.0031, RMSE: 0.0252\n",
      "Val - MSE: 0.0006, MAE: 0.0031, RMSE: 0.0252\n",
      "Train  - MSE: 0.0003, MAE: 0.0028, RMSE: 0.0166\n",
      "Val - MSE: 0.0003, MAE: 0.0028, RMSE: 0.0166\n",
      "dict_keys(['X_hat', 'G_hat', 'U_hat', 'V_hat', 'W_hat', 'A_hat'])\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# sys.path.append(r\"E:\\Code\\TDMIDR\")\n",
    "# Import our package\n",
    "from tdmidr.model import TDMIDR\n",
    "from tdmidr.trainer import train\n",
    "# Import rclr\n",
    "from rclr_utils.transforms import matrix_rclr, tensor_rclr, mask_value_only\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import collections\n",
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "params = {\n",
    "    'rank_1': 3,\n",
    "    'rank_2': 4,\n",
    "    'rank_3': 3,\n",
    "    'lambda_var': 0.006536173305988504,\n",
    "    'lambda_graph': 0.00013135506911867418,\n",
    "    'lambda_smooth': 3.854275076893828e-05,\n",
    "    'lambda_L1': 1.661774158540907e-05,\n",
    "    'lambda_L2': 0.07914674388602203\n",
    "}\n",
    "\n",
    "\n",
    "dense_tensor = mask_data.copy()\n",
    "dense_tensor_clr = tensor_rclr(np.nan_to_num(dense_tensor, nan=0))\n",
    "\n",
    "\n",
    "train_data = mask_data.copy()\n",
    "\n",
    "# rclr \n",
    "train_clr = tensor_rclr(np.nan_to_num(train_data, nan=0))\n",
    "\n",
    "\n",
    "train_clr = torch.tensor(train_clr, dtype=torch.float32).to(device)\n",
    "# mask_tensor = torch.from_numpy(dense_tensor_clr.copy()).float().to(device)\n",
    "mask_tensor = torch.from_numpy(mask_data.copy()).float().to(device)\n",
    "\n",
    "train_mask = torch.tensor(~np.isnan(mask_data), dtype=torch.bool).to(device)\n",
    "test_mask = train_mask.clone()\n",
    "LS1_tensor = torch.from_numpy(LS1.copy()).float().to(device)\n",
    "LS2_tensor = torch.from_numpy(np.array(LS2).copy()).float().to(device)\n",
    "\n",
    "\n",
    "M, N, T = train_data.shape\n",
    "\n",
    "model = TDMIDR(input_shape=(M, N, T), ranks=(3, 4, 3), lambda_var=params['lambda_var'], lambda_smooth=params['lambda_smooth'], \n",
    "                     lambda_graph=params['lambda_graph'], lambda_L2=params['lambda_L2'],lambda_L1=params['lambda_L1'], p=2, \n",
    "                     device=device, X=train_clr, mask=train_mask, L1=LS1_tensor, L2=LS2_tensor,use_hosvd=True).to(device)\n",
    "\n",
    "\n",
    "final_results = train(\n",
    "    model, train_clr, mask_tensor, train_mask, test_mask, num_epochs=400, lr=1e-3)\n",
    "\n",
    "print(final_results.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16275423",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T15:24:22.626659Z",
     "start_time": "2025-06-20T15:24:22.604833Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels：\n",
    "labels_df = pd.read_csv(\"E:/Code/github/SY.csv\", index_col=\"SubjectID\")\n",
    "\n",
    "y = labels_df['group'].values  #\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2001f23f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T15:25:38.315878Z",
     "start_time": "2025-06-20T15:25:38.162642Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==  1  ==\n",
      "==  2  ==\n",
      "==  3  ==\n",
      "==  4  ==\n",
      "==  5  ==\n",
      "AUC: 0.5719414225346743\n",
      "AUPR: 0.5813270913045259\n",
      "ACC: 0.5599999999999999\n",
      "F1-score: 0.6865153851802893\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, roc_auc_score, average_precision_score, adjusted_rand_score, normalized_mutual_info_score, silhouette_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "our_result = final_results[\"U_hat\"].cpu().detach().numpy() \n",
    "our_result\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "history_classification = {\n",
    "    'auc': [],\n",
    "    'aupr': [],\n",
    "    'accuracy': [],\n",
    "#     'recall': [],\n",
    "#     'precision': [],\n",
    "    'f1_score': []\n",
    "}\n",
    "\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(our_result)):\n",
    "    print(f\"==  {fold+1}  ==\")\n",
    "   \n",
    "    X_train, X_test = our_result[train_idx], our_result[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    \n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(48,), random_state=1234)\n",
    "    mlp.fit(X_train, y_train)\n",
    "\n",
    "    y_prob = mlp.predict_proba(X_test)[:, 1]  \n",
    "    \n",
    "        \n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_prob)\n",
    "\n",
    "\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "    best_idx = np.argmax(f1_scores)\n",
    "    best_threshold = thresholds[best_idx]\n",
    "\n",
    "    y_pred = (y_prob >= best_threshold).astype(int)\n",
    "\n",
    "    auc = roc_auc_score(y_test, y_prob)  # AUC (Area Under ROC Curve)\n",
    "    aupr = average_precision_score(y_test, y_prob)  # AUPR (Area Under Precision-Recall Curve)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "\n",
    "    history_classification['auc'].append(auc)\n",
    "    history_classification['aupr'].append(aupr)\n",
    "    history_classification['accuracy'].append(accuracy)\n",
    "#     history_classification['recall'].append(recall)\n",
    "#     history_classification['precision'].append(precision)\n",
    "    history_classification['f1_score'].append(f1)\n",
    "    \n",
    "\n",
    "print(f\"AUC: {np.mean(history_classification['auc'])}\")\n",
    "print(f\"AUPR: {np.mean(history_classification['aupr'])}\")\n",
    "print(f\"ACC: {np.mean(history_classification['accuracy'])}\")\n",
    "# print(f\"Recall: {np.mean(history_classification['recall'])}\")\n",
    "# print(f\"Precision: {np.mean(history_classification['precision'])}\")\n",
    "print(f\"F1-score: {np.mean(history_classification['f1_score'])}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53517ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
